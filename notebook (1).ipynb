{"cells":[{"source":"# Building Chatbots with the OpenAI API and Pinecone","metadata":{},"id":"8c8fde4c-9222-4265-b72b-8d7693520250","cell_type":"markdown"},{"source":"In this project, I aim to explore the fascinating world of AI chatbots. I'll will be using LangChain, OpenAI, and Pinecone vector DB, to build a chatbot capable of learning from the external world using **R**etrieval **A**ugmented **G**eneration (RAG).\n\nI'll will be using a dataset sourced from the Llama 2 ArXiv paper and other related papers to help our chatbot answer questions about the latest and greatest in the world of GenAI.\n\n\n![rag](rag.png)\n","metadata":{},"id":"3e302e1c-4c18-4c44-87fd-ba935c3a0853","cell_type":"markdown"},{"source":"## Before you begin","metadata":{},"id":"8231d2c6-275e-4399-b7cd-84e112831d08","cell_type":"markdown"},{"source":"First step is to get an [OpenAI API key](https://platform.openai.com/account/api-keys) and [Pinecone API key](https://app.pinecone.io). You can refer to *getting-started.ipynb* for steps on how to store these API keys in Workspace.","metadata":{},"id":"785d7fac-edb2-482f-be2b-c63dc2882103","cell_type":"markdown"},{"source":"## Task 0: Setup","metadata":{},"id":"a9274661-8d8c-4cc5-901e-5fc497866b89","cell_type":"markdown"},{"source":"Before we start building the chatbot, we need to install some Python libraries. Here's a brief overview of what each library does:\n\n- **langchain**: This is a library for GenAI. We'll use it to chain together different language models and components for our chatbot.\n- **openai**: This is the official OpenAI Python client. We'll use it to interact with the OpenAI API and generate responses for our chatbot.\n- **datasets**: This library provides a vast array of datasets for machine learning. We'll use it to load our knowledge base for the chatbot.\n- **pinecone-client**: This is the official Pinecone Python client. We'll use it to interact with the Pinecone vector DB where we will store our chatbot's knowledge base.\n- **tiktoken**: This is a library from OpenAI that allows you to count the number of tokens in a text string without making an API call.\n\nYou can install these libraries using pip like so:","metadata":{},"id":"2cf847fd-f8f8-49f6-9b43-0eb098239072","cell_type":"markdown"},{"source":"!pip install -qU \\\n    langchain==0.0.292 \\\n    openai==0.28.0 \\\n    datasets==2.10.1 \\\n    pinecone-client==2.2.4 \\\n    tiktoken==0.5.1","metadata":{"executionCancelledAt":null,"executionTime":8483,"lastExecutedAt":1698488761884,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"!pip install -qU \\\n    langchain==0.0.292 \\\n    openai==0.28.0 \\\n    datasets==2.10.1 \\\n    pinecone-client==2.2.4 \\\n    tiktoken==0.5.1","outputsMetadata":{"0":{"height":477,"type":"stream"}}},"id":"f96e3639-1515-47ce-9cab-21b2c8a43c64","cell_type":"code","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":"\u001b[33m  WARNING: The script tqdm is installed in '/home/repl/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33m  WARNING: The script pinecone is installed in '/home/repl/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33m  WARNING: The script langsmith is installed in '/home/repl/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33m  WARNING: The script openai is installed in '/home/repl/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33m  WARNING: The script langchain-server is installed in '/home/repl/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngremlinpython 3.6.1 requires aiohttp<=3.8.1,>=3.8.0, but you have aiohttp 3.8.6 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"}]},{"source":"## Task 1: Building a Chatbot","metadata":{},"id":"92a9caca-70fd-4ac0-aa15-1bee55c456d3","cell_type":"markdown"},{"source":"In this project I will be relying heavily on the LangChain library to bring together the different components needed for our chatbot. But let's first create a chatbot _without_ RAG.\n","metadata":{},"id":"b1fcd794-b29c-4010-8be0-651a452b2044","cell_type":"markdown"},{"source":"### Instructions\n\nInitialize the chat model object.\n\n- *Make sure you have defined the `OPENAI_API_KEY` environment variable and connected it. See the 'Setting up Workspace Integrations' section of getting-started.ipynb.*\n- From langchain's chat_models module, import `ChatOpenAI`.\n- Initialize a `ChatOpenAI` object with the `gpt-3.5-turbo` model. Assign to `chat`.","metadata":{},"id":"4cc8e24a-bd51-483a-81a6-e0c2d1e02c35","cell_type":"markdown"},{"source":"from langchain.chat_models import ChatOpenAI\n\nchat = ChatOpenAI(model_name=\"gpt-3.5-turbo\")","metadata":{"executionCancelledAt":null,"executionTime":1576,"lastExecutedAt":1698488763461,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from langchain.chat_models import ChatOpenAI\n\nchat = ChatOpenAI(model_name=\"gpt-3.5-turbo\")"},"id":"f81d6d0e-986b-49f4-94e1-7315a7f0bd67","cell_type":"code","execution_count":3,"outputs":[]},{"source":"### How are chats structured?\n\nChats with OpenAI's `gpt-3.5-turbo` and `gpt-4` chat models are typically structured (in plain text) like this:\n\n```\nSystem: You are a helpful assistant.\n\nUser: Hi AI, how are you today?\n\nAssistant: I'm great thank you. How can I help you?\n\nUser: I'd like to understand string theory.\n\nAssistant:\n```\n\nThe final `\"Assistant:\"` without a response is what would prompt the model to continue the conversation. In the official OpenAI `ChatCompletion` endpoint these would be passed to the model in a format like:\n\n```python\n[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"Hi AI, how are you today?\"},\n    {\"role\": \"assistant\", \"content\": \"I'm great thank you. How can I help you?\"}\n    {\"role\": \"user\", \"content\": \"I'd like to understand string theory.\"}\n]\n```\n\nIn LangChain there is a slightly different format. We use three _message_ objects like so:\n\n```python\nmessages = [\n    SystemMessage(content=\"You are a helpful assistant.\"),\n    HumanMessage(content=\"Hi AI, how are you today?\"),\n    AIMessage(content=\"I'm great thank you. How can I help you?\"),\n    HumanMessage(content=\"I'd like to understand string theory.\")\n]\n```\n\nThe format is very similar, we're just swapped the role of `\"user\"` for `HumanMessage`, and the role of `\"assistant\"` for `AIMessage`.","metadata":{},"id":"ab269915-cec5-4015-a848-25ac67ac2b5a","cell_type":"markdown"},{"source":"from langchain.schema import (\n    SystemMessage,\n    HumanMessage,\n    AIMessage\n)\n\nmessages = [\n    SystemMessage(content=\"You are a helpful assistant.\"),\n    HumanMessage(content=\"Hi AI, how are you today?\"),\n    AIMessage(content=\"I'm great thank you. How can I help you?\"),\n    HumanMessage(content=\"I'd like to understand string theory.\")\n]","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1698488763511,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from langchain.schema import (\n    SystemMessage,\n    HumanMessage,\n    AIMessage\n)\n\nmessages = [\n    SystemMessage(content=\"You are a helpful assistant.\"),\n    HumanMessage(content=\"Hi AI, how are you today?\"),\n    AIMessage(content=\"I'm great thank you. How can I help you?\"),\n    HumanMessage(content=\"I'd like to understand string theory.\")\n]"},"id":"8f542ae9-c4a0-41aa-a6b6-45585990c246","cell_type":"code","execution_count":4,"outputs":[]},{"source":"We generate the next response from the AI by passing these messages to the `ChatOpenAI` object. You can call `chat` as though it is a function.","metadata":{},"id":"7f6c51c7-bbbb-4f0f-b218-850221f3dcdf","cell_type":"markdown"},{"source":"### Instructions\n\nChat with GPT.\n\n- Pass the messages to the chat and get a response. Assign to `res`.\n- Print the response.","metadata":{},"id":"2a974f3e-c9ae-436c-880b-7634c334a786","cell_type":"markdown"},{"source":"res = chat(messages)\n\nres","metadata":{"executionCancelledAt":null,"executionTime":5331,"lastExecutedAt":1698488768843,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"res = chat(messages)\n\nres"},"id":"47ad31bf-db2a-444b-a011-26e9336a4e1e","cell_type":"code","execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":"AIMessage(content=\"String theory is a theoretical framework in physics that aims to describe the fundamental structure of the universe. It suggests that elementary particles, such as electrons and quarks, are not point-like particles, but rather tiny, vibrating strings. These strings have different vibrational modes, and each mode corresponds to a different particle with unique properties, such as mass and charge.\\n\\nThe theory incorporates both quantum mechanics and general relativity, attempting to reconcile the two fundamental theories of physics. It suggests that there are more dimensions than the four we commonly experience (three spatial dimensions and one time dimension), possibly up to 10 or even 11 dimensions. These extra dimensions are thought to be compactified or curled up, making them undetectable at our scale.\\n\\nString theory also proposes the existence of additional particles called gravitons, which mediate the force of gravity. This could potentially explain the nature of gravity within the framework of quantum mechanics.\\n\\nIt's important to note that string theory is still a work in progress, and there is no definitive experimental evidence to confirm its predictions. However, it has been influential in advancing our understanding of theoretical physics and has led to many fascinating mathematical developments.\\n\\nIf you have any specific questions about string theory, feel free to ask!\", additional_kwargs={}, example=False)"},"metadata":{},"execution_count":5}]},{"source":"Notice that the `AIMessage` object looks a bit like a dictionary. The most important element is `content`, which contains the chat text.","metadata":{},"id":"20487069-0c9e-4480-ba09-a6004686b3ba","cell_type":"markdown"},{"source":"### Instructions\n\nPrint only the contents of the response.","metadata":{},"id":"dd3463e9-26e8-4908-ab2c-aa78a147e79f","cell_type":"markdown"},{"source":"print(res.content)","metadata":{"executionCancelledAt":null,"executionTime":56,"lastExecutedAt":1698488768900,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"print(res.content)","outputsMetadata":{"0":{"height":377,"type":"stream"}}},"id":"38e8a99c-58ea-43ac-8918-64d42541a58d","cell_type":"code","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":"String theory is a theoretical framework in physics that aims to describe the fundamental structure of the universe. It suggests that elementary particles, such as electrons and quarks, are not point-like particles, but rather tiny, vibrating strings. These strings have different vibrational modes, and each mode corresponds to a different particle with unique properties, such as mass and charge.\n\nThe theory incorporates both quantum mechanics and general relativity, attempting to reconcile the two fundamental theories of physics. It suggests that there are more dimensions than the four we commonly experience (three spatial dimensions and one time dimension), possibly up to 10 or even 11 dimensions. These extra dimensions are thought to be compactified or curled up, making them undetectable at our scale.\n\nString theory also proposes the existence of additional particles called gravitons, which mediate the force of gravity. This could potentially explain the nature of gravity within the framework of quantum mechanics.\n\nIt's important to note that string theory is still a work in progress, and there is no definitive experimental evidence to confirm its predictions. However, it has been influential in advancing our understanding of theoretical physics and has led to many fascinating mathematical developments.\n\nIf you have any specific questions about string theory, feel free to ask!\n"}]},{"source":"Because `res` is just another `AIMessage` object, we can append it to `messages`, add another `HumanMessage`, and generate the next response in the conversation.","metadata":{},"id":"7090e9e9-880d-4b29-909a-a9653474c8b1","cell_type":"markdown"},{"source":"### Instructions\n\nContinue the conversation with GPT.\n\n- Append the latest AI response to messages.\n- Create a new human message. Assign to `prompt`.\n    - Use the content `\"Why do physicists believe it can produce a 'unified theory'?\"`\n- Append the prompt to messages.\n- Send the messages to GPT. Assign to `res`.\n- Print the contents of the response.","metadata":{},"id":"b25f1b56-22b0-414c-bc56-99ea90820f1a","cell_type":"markdown"},{"source":"messages.append(res)","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1698488768951,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"messages.append(res)","outputsMetadata":{"0":{"height":505,"type":"stream"}}},"id":"51e66e15-dc5d-4f5e-9db2-680f4c90546f","cell_type":"code","execution_count":7,"outputs":[]},{"source":"prompt = HumanMessage(content=\"Why do physicists believe it can produce a 'unified theory'?\")\n\nmessages.append(prompt)","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1698488769003,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"prompt = HumanMessage(content=\"Why do physicists believe it can produce a 'unified theory'?\")\n\nmessages.append(prompt)"},"id":"be31574f-4801-452e-94a1-a544e50fb4b1","cell_type":"code","execution_count":8,"outputs":[]},{"source":"messages","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1698488769056,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"messages"},"id":"7bc0c721-8eb2-4a20-8491-89a281480ea5","cell_type":"code","execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":"[SystemMessage(content='You are a helpful assistant.', additional_kwargs={}),\n HumanMessage(content='Hi AI, how are you today?', additional_kwargs={}, example=False),\n AIMessage(content=\"I'm great thank you. How can I help you?\", additional_kwargs={}, example=False),\n HumanMessage(content=\"I'd like to understand string theory.\", additional_kwargs={}, example=False),\n AIMessage(content=\"String theory is a theoretical framework in physics that aims to describe the fundamental structure of the universe. It suggests that elementary particles, such as electrons and quarks, are not point-like particles, but rather tiny, vibrating strings. These strings have different vibrational modes, and each mode corresponds to a different particle with unique properties, such as mass and charge.\\n\\nThe theory incorporates both quantum mechanics and general relativity, attempting to reconcile the two fundamental theories of physics. It suggests that there are more dimensions than the four we commonly experience (three spatial dimensions and one time dimension), possibly up to 10 or even 11 dimensions. These extra dimensions are thought to be compactified or curled up, making them undetectable at our scale.\\n\\nString theory also proposes the existence of additional particles called gravitons, which mediate the force of gravity. This could potentially explain the nature of gravity within the framework of quantum mechanics.\\n\\nIt's important to note that string theory is still a work in progress, and there is no definitive experimental evidence to confirm its predictions. However, it has been influential in advancing our understanding of theoretical physics and has led to many fascinating mathematical developments.\\n\\nIf you have any specific questions about string theory, feel free to ask!\", additional_kwargs={}, example=False),\n HumanMessage(content=\"Why do physicists believe it can produce a 'unified theory'?\", additional_kwargs={}, example=False)]"},"metadata":{},"execution_count":9}]},{"source":"res = chat(messages)\n\nprint(res.content)","metadata":{"executionCancelledAt":null,"executionTime":6628,"lastExecutedAt":1698488775684,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"res = chat(messages)\n\nprint(res.content)","outputsMetadata":{"0":{"height":417,"type":"stream"}}},"id":"4f68e1d4-4dcc-4dbe-b7ce-df321f90ae5c","cell_type":"code","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":"Physicists believe that string theory has the potential to produce a unified theory because it incorporates both quantum mechanics and general relativity, two fundamental theories that have been incredibly successful in explaining different aspects of the physical world but are incompatible with each other.\n\nQuantum mechanics describes the behavior of particles at the microscopic level, where the laws of probability and uncertainty play a significant role. On the other hand, general relativity describes the force of gravity and the behavior of massive objects at the cosmic scale, where spacetime is curved.\n\nHowever, when physicists try to combine quantum mechanics with general relativity, they encounter mathematical inconsistencies and infinities. This is known as the problem of quantum gravity. String theory attempts to overcome these issues by replacing point-like particles with tiny vibrating strings. By doing so, it introduces a fundamental length scale and resolves some of the mathematical difficulties that arise in combining quantum mechanics and general relativity.\n\nMoreover, string theory has the potential to explain the existence of all the fundamental forces of nature, including gravity, electromagnetism, the strong nuclear force, and the weak nuclear force, within a single framework. This is why it is often referred to as a \"theory of everything\" or a unified theory.\n\nWhile string theory is still a subject of ongoing research and debate, its mathematical elegance and potential to unify the fundamental forces make it an attractive candidate for a unified theory of physics.\n"}]},{"source":"## Task 2: Hallucinations","metadata":{},"id":"c536df54-a985-401e-99e7-212004379618","cell_type":"markdown"},{"source":"We have our chatbot, but as mentioned—the knowledge of LLMs can be limited. The reason for this is that LLMs learn all they know during training. An LLM essentially compresses the \"world\" as seen in the training data into the internal parameters of the model. We call this knowledge the _parametric knowledge_ of the model.\n\n\n\nBy default, LLMs have no access to the external world.\n\n![langchain-no-access-to-world](langchain-no-access-to-world.png)\n\nThis means that GPT (or any other LLM) will perform badly on some types of question.\n\n* The chatbot doesn't know about recent events. How does it respond if you ask about the weather in your city today?\n* It can't answer questions about recent code or recent products. Try asking it `\"Can you tell me about the LLMChain in LangChain?\"` or `\"What was the latest course released on DataCamp?\"`\n* It can't answer questions about confidential corporate information that hasn't been released into the internet.","metadata":{},"id":"e257b696-4c54-4412-9534-7bf57a47cfc3","cell_type":"markdown"},{"source":"### Instructions\n\nAsk GPT about the new (and very popular) Llama 2 LLM.\n\n- Append the latest AI response to `messages`.\n- Create a new human message. Assign to `prompt`.\n    - Use the content `\"What is so special about Llama 2?\"`.\n- Append the prompt to `messages`.\n- Send the messages to GPT. Assign to `res`.\n- Print the contents of the response.","metadata":{},"id":"61ae0a3c-6d1a-4616-9cf0-871c1dd4b5d5","cell_type":"markdown"},{"source":"print(len(messages))\nmessages.append(res)\nprint(len(messages))","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1698488775732,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"print(len(messages))\nmessages.append(res)\nprint(len(messages))","outputsMetadata":{"0":{"height":57,"type":"stream"}}},"id":"5af4c597-b1b6-4159-9a86-876789695fab","cell_type":"code","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":"6\n7\n"}]},{"source":"prompt = HumanMessage(content=\"What is so special about Llama 2?\")\nmessages.append(prompt)\n\nres = chat(messages)\nprint(res.content)","metadata":{"executionCancelledAt":null,"executionTime":1967,"lastExecutedAt":1698488777699,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"prompt = HumanMessage(content=\"What is so special about Llama 2?\")\nmessages.append(prompt)\n\nres = chat(messages)\nprint(res.content)","outputsMetadata":{"0":{"height":77,"type":"stream"}}},"id":"c3e22ec5-7a01-46a2-96b9-ee2dda555932","cell_type":"code","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":"I'm sorry, but I don't have any information about a specific entity or concept referred to as \"Llama 2.\" It's possible that you might be referring to something that I am not familiar with. Could you please provide more context or clarify your question?\n"}]},{"source":"### Confidently wrong: hallucinations from LLMs\n\nOur chatbot can no longer help us, it doesn't contain the information we need to answer the question. It was very clear from this answer that the LLM doesn't know the information, but sometimes an LLM may respond like it _does_ know the answer—and this can be very hard to detect. See this example from the earliest version of GPT-4 in the OpenAI Playground:\n\n![llm-chain-hallucination](llm-chain-hallucination.png)\n\nOpenAI have since adjusted the behavior for this particular example as we can see below:\n","metadata":{},"id":"632d8027-3fe6-4e5d-ba5e-bbd261c6e9d6","cell_type":"markdown"},{"source":"messages.append(res)\nprompt = HumanMessage(content=\"Can you tell me about the LLMChain in LangChain?\")\nmessages.append(prompt)\n\nres = chat(messages)\nprint(res.content)","metadata":{"executionCancelledAt":null,"executionTime":1962,"lastExecutedAt":1698488779661,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"messages.append(res)\nprompt = HumanMessage(content=\"Can you tell me about the LLMChain in LangChain?\")\nmessages.append(prompt)\n\nres = chat(messages)\nprint(res.content)","outputsMetadata":{"0":{"height":97,"type":"stream"}}},"id":"13e182b4-3b48-4d28-88dd-27abc9ad4a1c","cell_type":"code","execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":"I apologize, but I'm not familiar with the specific terms \"LLMChain\" or \"LangChain.\" It's possible that these terms are related to a particular project, technology, or concept that I am not aware of. Without more context or information, I won't be able to provide you with a detailed explanation. Could you please provide more details or clarify your question further?\n"}]},{"source":"There is another way of feeding knowledge into LLMs. It is called _source knowledge_ and it refers to any information fed into the LLM via the prompt. We can try that with the LLMChain question. We can take a description of this object from the LangChain documentation.","metadata":{},"id":"ef46c06c-d226-49ce-b467-78408945ff4f","cell_type":"markdown"},{"source":"### Instructions\n\nCreate a string of knowledge about chains.\n\n- *Read the descriptions of LLMChains, Chains, and LangChain given in `llmchain_information`.*\n- Combine the list of description strings into a single string. Assign to `source_knowledge`.","metadata":{},"id":"9e8fb83d-8c94-4d11-b21a-12c455a7f873","cell_type":"markdown"},{"source":"# A description of LLMChains, Chains, and LangChain \nllmchain_information = [\n    \"A LLMChain is the most common type of chain. It consists of a PromptTemplate, a model (either an LLM or a ChatModel), and an optional output parser. This chain takes multiple input variables, uses the PromptTemplate to format them into a prompt. It then passes that to the model. Finally, it uses the OutputParser (if provided) to parse the output of the LLM into a final format.\",\n    \"Chains is an incredibly generic concept which returns to a sequence of modular components (or other chains) combined in a particular way to accomplish a common use case.\",\n    \"LangChain is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also: (1) Be data-aware: connect a language model to other sources of data, (2) Be agentic: Allow a language model to interact with its environment. As such, the LangChain framework is designed with the objective in mind to enable those types of applications.\"\n]\nlen(llmchain_information)","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1698488779716,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# A description of LLMChains, Chains, and LangChain \nllmchain_information = [\n    \"A LLMChain is the most common type of chain. It consists of a PromptTemplate, a model (either an LLM or a ChatModel), and an optional output parser. This chain takes multiple input variables, uses the PromptTemplate to format them into a prompt. It then passes that to the model. Finally, it uses the OutputParser (if provided) to parse the output of the LLM into a final format.\",\n    \"Chains is an incredibly generic concept which returns to a sequence of modular components (or other chains) combined in a particular way to accomplish a common use case.\",\n    \"LangChain is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also: (1) Be data-aware: connect a language model to other sources of data, (2) Be agentic: Allow a language model to interact with its environment. As such, the LangChain framework is designed with the objective in mind to enable those types of applications.\"\n]\nlen(llmchain_information)"},"id":"711778a5-76d5-40d2-8ed1-2b12a89a474d","cell_type":"code","execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":"3"},"metadata":{},"execution_count":14}]},{"source":"source_knowledge = \"\\n\".join(llmchain_information)\nsource_knowledge","metadata":{"executionCancelledAt":null,"executionTime":56,"lastExecutedAt":1698488779772,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"source_knowledge = \"\\n\".join(llmchain_information)\nsource_knowledge"},"id":"f63762f2-0cb2-48ee-8d51-8fc6b3165fcd","cell_type":"code","execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":"'A LLMChain is the most common type of chain. It consists of a PromptTemplate, a model (either an LLM or a ChatModel), and an optional output parser. This chain takes multiple input variables, uses the PromptTemplate to format them into a prompt. It then passes that to the model. Finally, it uses the OutputParser (if provided) to parse the output of the LLM into a final format.\\nChains is an incredibly generic concept which returns to a sequence of modular components (or other chains) combined in a particular way to accomplish a common use case.\\nLangChain is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also: (1) Be data-aware: connect a language model to other sources of data, (2) Be agentic: Allow a language model to interact with its environment. As such, the LangChain framework is designed with the objective in mind to enable those types of applications.'"},"metadata":{},"execution_count":15}]},{"source":"We can feed this additional knowledge into our prompt with some instructions telling the LLM how we'd like it to use this information alongside our original query.","metadata":{},"id":"961fe8f0-4b6a-4227-8b40-0ab501c13ee5","cell_type":"markdown"},{"source":"### Instructions\n\n- Define a question. Assign to `query`.\n    - Use the text `\"Can you tell me about the LLMChain in LangChain?\"`\n- Create an augmented prompt containing the context and query. Assign to `augmented_prompt`.\n\n        augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n\n        Contexts:\n        {source_knowledge}\n\n        Query: {query}\"\"\"","metadata":{},"id":"a18cd1f5-ace4-4abd-b139-6d6e163e9c3d","cell_type":"markdown"},{"source":"query = \"Can you tell me about the LLMChain in LangChain?\"\n\naugmented_prompt = f\"\"\"Using the contexts below, answer the query. If some information is not provided within\nthe contexts below, do not include, and if the query cannot be answered with the below information, say \"I don't know\".\n\nContexts:\n{source_knowledge}\n\nQuery: {query}\"\"\"","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1698488779819,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"query = \"Can you tell me about the LLMChain in LangChain?\"\n\naugmented_prompt = f\"\"\"Using the contexts below, answer the query. If some information is not provided within\nthe contexts below, do not include, and if the query cannot be answered with the below information, say \"I don't know\".\n\nContexts:\n{source_knowledge}\n\nQuery: {query}\"\"\""},"id":"58a71fbf-6b81-42f5-8073-ddfd3139e351","cell_type":"code","execution_count":16,"outputs":[]},{"source":"print(augmented_prompt)","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1698488779872,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"print(augmented_prompt)","outputsMetadata":{"0":{"height":357,"type":"stream"}}},"id":"99e5faa0-e6dd-43a1-ba33-96fdeea31f9e","cell_type":"code","execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":"Using the contexts below, answer the query. If some information is not provided within\nthe contexts below, do not include, and if the query cannot be answered with the below information, say \"I don't know\".\n\nContexts:\nA LLMChain is the most common type of chain. It consists of a PromptTemplate, a model (either an LLM or a ChatModel), and an optional output parser. This chain takes multiple input variables, uses the PromptTemplate to format them into a prompt. It then passes that to the model. Finally, it uses the OutputParser (if provided) to parse the output of the LLM into a final format.\nChains is an incredibly generic concept which returns to a sequence of modular components (or other chains) combined in a particular way to accomplish a common use case.\nLangChain is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also: (1) Be data-aware: connect a language model to other sources of data, (2) Be agentic: Allow a language model to interact with its environment. As such, the LangChain framework is designed with the objective in mind to enable those types of applications.\n\nQuery: Can you tell me about the LLMChain in LangChain?\n"}]},{"source":"Now we feed this into our chatbot as we did before.\n\nDon't append the previous AI message, since it wasn't a good answer.","metadata":{},"id":"686b36f9-9107-4099-b0da-22e60e4b17e6","cell_type":"markdown"},{"source":"print(messages[-1])","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1698488779920,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"print(messages[-1])","outputsMetadata":{"0":{"height":37,"type":"stream"}}},"id":"a7e0ee47-69f2-4f21-b48d-279e9ae5df3e","cell_type":"code","execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":"content='Can you tell me about the LLMChain in LangChain?' additional_kwargs={} example=False\n"}]},{"source":"messages[-1] = HumanMessage(content=augmented_prompt)","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1698488779971,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"messages[-1] = HumanMessage(content=augmented_prompt)","outputsMetadata":{"0":{"height":368,"type":"stream"}}},"id":"901893e6-726d-4a42-805f-ee2d24b3b8a2","cell_type":"code","execution_count":19,"outputs":[]},{"source":"res = chat(messages)\nprint(res.content)","metadata":{"executionCancelledAt":null,"executionTime":4842,"lastExecutedAt":1698488784813,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"res = chat(messages)\nprint(res.content)","outputsMetadata":{"0":{"height":237,"type":"stream"}}},"id":"ebbf365d-0215-4f6f-bb5b-146323b559b4","cell_type":"code","execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":"Based on the provided context, it appears that the LLMChain is a type of chain within the LangChain framework for developing applications powered by language models. The LLMChain consists of a PromptTemplate, a model (either an LLM or a ChatModel), and an optional output parser.\n\nThe purpose of the LLMChain is to take multiple input variables, format them into a prompt using the PromptTemplate, and then pass that prompt to the language model (LLM or ChatModel). Finally, if an OutputParser is provided, it is used to parse the output of the language model into a final format.\n\nIn summary, the LLMChain is a component of the LangChain framework that facilitates the integration of language models into applications by providing a structure for handling input variables, formatting prompts, and parsing the model's output.\n"}]},{"source":"The quality of this answer is phenomenal! This is made possible thanks to the idea of augmented our query with external knowledge (source knowledge). There's just one problem—how do we get this information in the first place?\n\nWe learned in the previous code-alongs about Pinecone and vector databases. Well, they can help us here too. But first, we'll need a dataset.","metadata":{},"id":"30ae1f20-1e41-4e4f-a08e-09d0167170ba","cell_type":"markdown"},{"source":"## Task 3: Importing the Data","metadata":{},"id":"97fa3cfe-9223-4593-85fd-6c21f788d46e","cell_type":"markdown"},{"source":"In this task, we will be importing our data. We will be using the Hugging Face Datasets library and [the `\"jamescalam/llama-2-arxiv-papers\"` dataset](https://huggingface.co/datasets/jamescalam/llama-2-arxiv-papers-chunked). This dataset contains a collection of ArXiv papers which will serve as the external knowledge base for our chatbot.","metadata":{},"id":"d6f4cd0f-4d29-4667-bf90-2603bae73759","cell_type":"markdown"},{"source":"from datasets import load_dataset\n\ndata = load_dataset(\"jamescalam/llama-2-arxiv-papers-chunked\", split=\"train\")\ndata","metadata":{"executionCancelledAt":null,"executionTime":1388,"lastExecutedAt":1698488786201,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from datasets import load_dataset\n\ndata = load_dataset(\"jamescalam/llama-2-arxiv-papers-chunked\", split=\"train\")\ndata","outputsMetadata":{"1":{"height":77,"type":"stream"},"6":{"height":77,"type":"stream"}}},"id":"16f97002-b358-4a33-bb50-0401feda259b","cell_type":"code","execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/409 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e30f7df755154538834f2c14a0b67ffb"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"Downloading and preparing dataset json/jamescalam--llama-2-arxiv-papers-chunked to /home/repl/.cache/huggingface/datasets/jamescalam___json/jamescalam--llama-2-arxiv-papers-chunked-ea255a807f3039a6/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51...\n"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5761513562b3444eb5758bc1c7260888"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/14.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19d5687bb51b4bcdaab590c4efab4685"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a137673328214c25a78d6804d3ca86b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de4cafa19cb349c9be2b5f61434f9e1a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"Dataset json downloaded and prepared to /home/repl/.cache/huggingface/datasets/jamescalam___json/jamescalam--llama-2-arxiv-papers-chunked-ea255a807f3039a6/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51. Subsequent calls will reuse this data.\n"},{"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['doi', 'chunk-id', 'chunk', 'id', 'title', 'summary', 'source', 'authors', 'categories', 'comment', 'journal_ref', 'primary_category', 'published', 'updated', 'references'],\n    num_rows: 4838\n})"},"metadata":{},"execution_count":21}]},{"source":"### Instructions\n\nPrint a record of dataset to get a feel for what they contain.","metadata":{},"id":"796c12aa-e78a-4e62-9205-73cc6f3908cd","cell_type":"markdown"},{"source":"data[0]","metadata":{"executionCancelledAt":null,"executionTime":383,"lastExecutedAt":1698488786584,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"data[0]"},"id":"0e4c8dfd-2c65-4d2f-8ae1-d356daf0a3d8","cell_type":"code","execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":"{'doi': '1102.0183',\n 'chunk-id': '0',\n 'chunk': 'High-Performance Neural Networks\\nfor Visual Object Classi\\x0ccation\\nDan C. Cire\\x18 san, Ueli Meier, Jonathan Masci,\\nLuca M. Gambardella and J\\x7f urgen Schmidhuber\\nTechnical Report No. IDSIA-01-11\\nJanuary 2011\\nIDSIA / USI-SUPSI\\nDalle Molle Institute for Arti\\x0ccial Intelligence\\nGalleria 2, 6928 Manno, Switzerland\\nIDSIA is a joint institute of both University of Lugano (USI) and University of Applied Sciences of Southern Switzerland (SUPSI),\\nand was founded in 1988 by the Dalle Molle Foundation which promoted quality of life.\\nThis work was partially supported by the Swiss Commission for Technology and Innovation (CTI), Project n. 9688.1 IFF:\\nIntelligent Fill in Form.arXiv:1102.0183v1  [cs.AI]  1 Feb 2011\\nTechnical Report No. IDSIA-01-11 1\\nHigh-Performance Neural Networks\\nfor Visual Object Classi\\x0ccation\\nDan C. Cire\\x18 san, Ueli Meier, Jonathan Masci,\\nLuca M. Gambardella and J\\x7f urgen Schmidhuber\\nJanuary 2011\\nAbstract\\nWe present a fast, fully parameterizable GPU implementation of Convolutional Neural\\nNetwork variants. Our feature extractors are neither carefully designed nor pre-wired, but',\n 'id': '1102.0183',\n 'title': 'High-Performance Neural Networks for Visual Object Classification',\n 'summary': 'We present a fast, fully parameterizable GPU implementation of Convolutional\\nNeural Network variants. Our feature extractors are neither carefully designed\\nnor pre-wired, but rather learned in a supervised way. Our deep hierarchical\\narchitectures achieve the best published results on benchmarks for object\\nclassification (NORB, CIFAR10) and handwritten digit recognition (MNIST), with\\nerror rates of 2.53%, 19.51%, 0.35%, respectively. Deep nets trained by simple\\nback-propagation perform better than more shallow ones. Learning is\\nsurprisingly rapid. NORB is completely trained within five epochs. Test error\\nrates on MNIST drop to 2.42%, 0.97% and 0.48% after 1, 3 and 17 epochs,\\nrespectively.',\n 'source': 'http://arxiv.org/pdf/1102.0183',\n 'authors': ['Dan C. Cireşan',\n  'Ueli Meier',\n  'Jonathan Masci',\n  'Luca M. Gambardella',\n  'Jürgen Schmidhuber'],\n 'categories': ['cs.AI', 'cs.NE'],\n 'comment': '12 pages, 2 figures, 5 tables',\n 'journal_ref': None,\n 'primary_category': 'cs.AI',\n 'published': '20110201',\n 'updated': '20110201',\n 'references': []}"},"metadata":{},"execution_count":22}]},{"source":"### Dataset Summary\n\nThe dataset we are using is sourced from the Llama 2 ArXiv papers. It is a collection of academic papers from ArXiv, a repository of electronic preprints approved for publication after moderation. Each entry in the dataset represents a \"chunk\" of text from these papers.\n\nBecause most **L**arge **L**anguage **M**odels (LLMs) only contain knowledge of the world as it was during training, they cannot answer our questions about Llama 2—at least not without this data.","metadata":{},"id":"7901bcab-0c5e-4bc1-944e-ebd13d9284da","cell_type":"markdown"},{"source":"## Task 4: Building the Knowledge Base","metadata":{},"id":"7af0beaa-68f8-4cc3-831f-1118e79f45b3","cell_type":"markdown"},{"source":"We now have a dataset that can serve as our chatbot knowledge base. Our next task is to transform that dataset into the knowledge base that our chatbot can use. To do this we must use an embedding model and vector database.","metadata":{},"id":"92558679-3d66-419d-b30d-783456b992e5","cell_type":"markdown"},{"source":"### Workflow\n\nThe workflow for setting up a chatbot is much the same as for setting up semantic serach and retrieval augmented generation, as seen in previous code-alongs.\n\n- Initialize your connection to the Pinecone vector DB.\n- Create an index (remember to consider the dimensionality of `text-embedding-ada-002`).\n- Initialize OpenAI's `text-embedding-ada-002` model with LangChain.\n- Populate the index with records (in this case from the Llama 2 dataset).","metadata":{},"id":"2f5e123a-23f5-4fbb-a8dd-226dbdbd5b7f","cell_type":"markdown"},{"source":"import os\nimport pinecone\n\npinecone.init(\n    api_key=os.environ[\"PINECONE_API_KEY\"],\n    environment=os.environ[\"PINECONE_ENVIRONMENT\"]\n)","metadata":{"executionCancelledAt":null,"executionTime":659,"lastExecutedAt":1698488788386,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import os\nimport pinecone\n\npinecone.init(\n    api_key=os.environ[\"PINECONE_API_KEY\"],\n    environment=os.environ[\"PINECONE_ENVIRONMENT\"]\n)"},"id":"0be5dcfe-1fd1-432c-9c95-77572f27e2fe","cell_type":"code","execution_count":23,"outputs":[]},{"source":"Then we initialize the index. We will be using OpenAI's `text-embedding-ada-002` model for creating the embeddings, so we set the `dimension` to `1536`.","metadata":{},"id":"6536757a-943a-4b06-bba2-6bfe4152d170","cell_type":"markdown"},{"source":"### Instructions\n\nCreate a vector index in the Pinecone database.\n\n- Import the time package.\n- Choose a name for the vector index. Assign to `index_name`.\n- Check if index_name is not in Pinecone's list of existing indexes.\n    -  Create an index named index_name, dimension 1536, cosine similarity as its metric.\n    -  While the index status is not ready, sleep for one second.\n- Connect to the index. Assign to `index`.\n- View the index stats.","metadata":{},"id":"e1b833dd-0ed2-4547-b0c4-18e9a105963f","cell_type":"markdown"},{"source":"import time\n\nindex_name = \"llama-2-rag\"\n\nif index_name not in pinecone.list_indexes():\n    pinecone.create_index(\n        index_name, dimension=1536, metric=\"cosine\"\n    )\n    while not pinecone.describe_index(index_name).status[\"ready\"]:\n        time.sleep(1)\n        \nindex = pinecone.Index(index_name)","metadata":{"executionCancelledAt":null,"executionTime":33401,"lastExecutedAt":1698489011979,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import time\n\nindex_name = \"llama-2-rag\"\n\nif index_name not in pinecone.list_indexes():\n    pinecone.create_index(\n        index_name, dimension=1536, metric=\"cosine\"\n    )\n    while not pinecone.describe_index(index_name).status[\"ready\"]:\n        time.sleep(1)\n        \nindex = pinecone.Index(index_name)"},"id":"a9c31353-0b6c-40e4-8b13-582b39004f55","cell_type":"code","execution_count":24,"outputs":[]},{"source":"index.describe_index_stats()","metadata":{"executionCancelledAt":null,"executionTime":232,"lastExecutedAt":1698489028339,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"index.describe_index_stats()"},"id":"ea941ab8-99ab-4600-b035-7a892b0bd88d","cell_type":"code","execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":"{'dimension': 1536,\n 'index_fullness': 0.0,\n 'namespaces': {},\n 'total_vector_count': 0}"},"metadata":{},"execution_count":25}]},{"source":"Our index is now ready but it's empty. It is a vector index, so it needs vectors. As mentioned, to create these vector embeddings we will OpenAI's `text-embedding-ada-002` model—we can access it via LangChain.","metadata":{},"id":"79733e18-cb8a-4b0a-9335-d0bdc90529ff","cell_type":"markdown"},{"source":"### Instructions\n\nCreate an embeddings model.\n\n- From langchain's embeddings module and openai submodule, import `OpenAIEmbeddings`.\n- Create an embedings model object for `text-embedding-ada-002`. Assign to `embed_model`.","metadata":{},"id":"b97b2f2c-828e-4517-b160-188977e9bbb5","cell_type":"markdown"},{"source":"from langchain.embeddings.openai import OpenAIEmbeddings\n\nembed_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1698489100619,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from langchain.embeddings.openai import OpenAIEmbeddings\n\nembed_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"},"id":"7fc53547-8e89-4700-9a69-95bca1bedd30","cell_type":"code","execution_count":26,"outputs":[]},{"source":"Using this model we can create embeddings like so:","metadata":{},"id":"a7c8de50-0543-4ae0-92c0-1da97803f841","cell_type":"markdown"},{"source":"texts = [\n    \"this is a sentence\",\n    \"this is another sentence\"\n]\n\nres = embed_model.embed_documents(texts=texts)\nlen(res), len(res[0])","metadata":{"executionCancelledAt":null,"executionTime":1272,"lastExecutedAt":1698489196826,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"texts = [\n    \"this is a sentence\",\n    \"this is another sentence\"\n]\n\nres = embed_model.embed_documents(texts=texts)\nlen(res), len(res[0])"},"id":"5b86b13a-591f-4b8e-b3cc-33c24c076d5b","cell_type":"code","execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":"(2, 1536)"},"metadata":{},"execution_count":27}]},{"source":"From this we get two (aligning to our two chunks of text) 1536-dimensional embeddings.\n\nWe're now ready to embed and index all our our data! We do this by looping through our dataset and embedding and inserting everything in batches.","metadata":{},"id":"f7f7f8ee-beb7-4dd0-86fa-cddf0d130d7e","cell_type":"markdown"},{"source":"data[0][\"doi\"], data[1][\"doi\"], data[0][\"chunk-id\"], data[1][\"chunk-id\"]","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1698489533412,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"data[0][\"doi\"], data[1][\"doi\"], data[0][\"chunk-id\"], data[1][\"chunk-id\"]"},"id":"7f35bdc2-c8b2-458b-a5b8-636115c50bec","cell_type":"code","execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":"('1102.0183', '1102.0183', '0', '1')"},"metadata":{},"execution_count":31}]},{"source":"data","metadata":{"executionCancelledAt":null,"executionTime":12,"lastExecutedAt":1698489659921,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"data"},"id":"1a9e78d0-8e0e-4503-b97f-713c2e475565","cell_type":"code","execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['doi', 'chunk-id', 'chunk', 'id', 'title', 'summary', 'source', 'authors', 'categories', 'comment', 'journal_ref', 'primary_category', 'published', 'updated', 'references'],\n    num_rows: 4838\n})"},"metadata":{},"execution_count":32}]},{"source":"from tqdm import tqdm\n\ndata = data.to_pandas()\n\nbatch_size = 100\n\nfor i in tqdm(range(0, len(data), batch_size)):\n    i_end = min(i+batch_size, len(data))\n    batch = data.iloc[i:i_end]\n    ids = [f\"{x['doi']}-{x['chunk-id']}\" for _, x in batch.iterrows()]\n    texts = [x[\"chunk\"] for _, x in batch.iterrows()]\n    embeds = embed_model.embed_documents(texts)\n    metadata = [\n        {\"text\": x[\"chunk\"],\n         \"title\": x[\"title\"],\n         \"source\": x[\"source\"]} for _, x in  batch.iterrows()\n    ]\n    # [(id1, embed1, metadata1), (id2, embed2, metadata2), ...]\n    index.upsert(vectors=zip(ids, embeds, metadata))","metadata":{"executionCancelledAt":null,"executionTime":74075,"lastExecutedAt":1698489896718,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from tqdm import tqdm\n\ndata = data.to_pandas()\n\nbatch_size = 100\n\nfor i in tqdm(range(0, len(data), batch_size)):\n    i_end = min(i+batch_size, len(data))\n    batch = data.iloc[i:i_end]\n    ids = [f\"{x['doi']}-{x['chunk-id']}\" for _, x in batch.iterrows()]\n    texts = [x[\"chunk\"] for _, x in batch.iterrows()]\n    embeds = embed_model.embed_documents(texts)\n    metadata = [\n        {\"text\": x[\"chunk\"],\n         \"title\": x[\"title\"],\n         \"source\": x[\"source\"]} for _, x in  batch.iterrows()\n    ]\n    # [(id1, embed1, metadata1), (id2, embed2, metadata2), ...]\n    index.upsert(vectors=zip(ids, embeds, metadata))","outputsMetadata":{"0":{"height":37,"type":"stream"}}},"id":"ae4bf4ac-16ff-4c70-baef-dcd2f746a200","cell_type":"code","execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":"100%|██████████| 49/49 [01:14<00:00,  1.51s/it]\n"}]},{"source":"We can check that the vector index has been populated using `describe_index_stats` like before:","metadata":{},"id":"58db36f2-1ba2-4fdb-9e72-aabe8fc16882","cell_type":"markdown"},{"source":"### Instructions\n\nCheck on updates to the vector index now that it contains the ArXiv dataset.\n\n- View the index stats again.\n- *What has changed since you last looked?*","metadata":{},"id":"2235eb44-2990-4d7e-ab51-6e36263d685f","cell_type":"markdown"},{"source":"index.describe_index_stats()","metadata":{"executionCancelledAt":null,"executionTime":75,"lastExecutedAt":1698489901904,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"index.describe_index_stats()"},"id":"48aa5c57-c923-49fc-b1dd-d60f6fa26d64","cell_type":"code","execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":"{'dimension': 1536,\n 'index_fullness': 0.0,\n 'namespaces': {'': {'vector_count': 4838}},\n 'total_vector_count': 4838}"},"metadata":{},"execution_count":34}]},{"source":"## Task 5: Retrieval Augmented Generation","metadata":{},"id":"6b90e6fc-f627-40a2-8276-7df46b5d7155","cell_type":"markdown"},{"source":"In the previous task we built a fully-fledged knowledge base. Now it's time to connect that knowledge base to our chatbot. To do that we'll be diving back into LangChain and reusing our template prompt from earlier.\n\n### Workflow\n\n* Create a LangChain `vectorstore` object using our `index` and `embed_model`.\n* Try searching for relevant information about Llama 2.\n* Create a function (`augment_prompt`) that can take our query, retrieve information using the `vectorstore`, and merge them all into a single retrieval-augmented prompt.\n* Try asking the chatbot Llama 2 questions with and without RAG, comparing the differences.","metadata":{},"id":"946741c8-6ad8-4aa4-afe4-e3357929918b","cell_type":"markdown"},{"source":"To use LangChain's RAG pipeline we need to load the LangChain abstraction for a vector index, called a `vectorstore`. We pass in our vector `index` to initialize the object.","metadata":{},"id":"320fa5d8-9642-4c7f-9a9f-9665b9c20475","cell_type":"markdown"},{"source":"from langchain.vectorstores import Pinecone\n\ntext_field = \"text\"\n\nvectorstore = Pinecone(\n    index, embed_model.embed_query, text_field\n)","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1698489995687,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from langchain.vectorstores import Pinecone\n\ntext_field = \"text\"\n\nvectorstore = Pinecone(\n    index, embed_model.embed_query, text_field\n)"},"id":"d91af8d9-9e0b-4246-ba92-08769b7f6017","cell_type":"code","execution_count":35,"outputs":[]},{"source":"Using this `vectorstore` we can already query the index and see if we have any relevant information given our question about Llama 2.","metadata":{},"id":"e7231db5-b65e-431c-87fb-e4600b5901e1","cell_type":"markdown"},{"source":"### Instructions\n\nPerform similarity search against a question.\n\n- Define a question. Assign to query.\n    - Use the text `\"What is so special about Llama 2?\"`.\n- Perform a similarity search for the query, returning 3 results.","metadata":{},"id":"e92e91fc-f4b1-437c-a8eb-e4ee507c0b19","cell_type":"markdown"},{"source":"query = \"What is so special about Llama 2?\"\n\nvectorstore.similarity_search(query, k=3)","metadata":{"executionCancelledAt":null,"executionTime":304,"lastExecutedAt":1698490032321,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"query = \"What is so special about Llama 2?\"\n\nvectorstore.similarity_search(query, k=3)"},"id":"11343325-0736-4b08-b85b-1d4735a0402d","cell_type":"code","execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":"[Document(page_content='Alan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom\\x03\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and ﬁne-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur ﬁne-tuned LLMs, called L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosedsource models. We provide a detailed description of our approach to ﬁne-tuning and safety', metadata={'source': 'http://arxiv.org/pdf/2307.09288', 'title': 'Llama 2: Open Foundation and Fine-Tuned Chat Models'}),\n Document(page_content='asChatGPT,BARD,andClaude. TheseclosedproductLLMsareheavilyﬁne-tunedtoalignwithhuman\\npreferences, which greatly enhances their usability and safety. This step can require signiﬁcant costs in\\ncomputeandhumanannotation,andisoftennottransparentoreasilyreproducible,limitingprogresswithin\\nthe community to advance AI alignment research.\\nIn this work, we develop and release Llama 2, a family of pretrained and ﬁne-tuned LLMs, L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle and\\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc , at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested,\\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc models generally perform better than existing open-source models. They also appear to\\nbe on par with some of the closed-source models, at least on the human evaluations we performed (see', metadata={'source': 'http://arxiv.org/pdf/2307.09288', 'title': 'Llama 2: Open Foundation and Fine-Tuned Chat Models'}),\n Document(page_content='Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aur’elien Rodriguez, Armand Joulin, Edouard\\nGrave, and Guillaume Lample. Llama: Open and eﬃcient foundation language models. arXiv preprint\\narXiv:2302.13971 , 2023.\\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser,\\nand Illia Polosukhin. Attention is all you need, 2017.\\nOriol Vinyals, Igor Babuschkin, Wojciech M Czarnecki, Michaël Mathieu, Andrew Dudzik, Junyoung Chung,\\nDavid H Choi, Richard Powell, Timo Ewalds, Petko Georgiev, et al. Grandmaster level in starcraft ii using\\nmulti-agent reinforcement learning. Nature, 575(7782):350–354, 2019.\\nYizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and HannanehHajishirzi. Self-instruct: Aligninglanguagemodel withselfgeneratedinstructions. arXivpreprint', metadata={'source': 'http://arxiv.org/pdf/2307.09288', 'title': 'Llama 2: Open Foundation and Fine-Tuned Chat Models'})]"},"metadata":{},"execution_count":36}]},{"source":"We return a lot of text here and it's not that clear what we need or what is relevant. Fortunately, our LLM will be able to parse this information much faster than us. All we need is to connect the output from our `vectorstore` to our `chat` chatbot. To do that we can use the same logic as we used earlier.","metadata":{},"id":"a4c5d7a5-9429-4d85-b8a5-f85aa9ae8654","cell_type":"markdown"},{"source":"### Instructions\n\nRun the code to define a function to augment a prompt with knowledge base results.","metadata":{},"id":"ed80b668-6796-4795-8138-711e0325f050","cell_type":"markdown"},{"source":"def augment_prompt(query: str):\n    results = vectorstore.similarity_search(query, k=3)\n    source_knowledge = \"\\n\".join([x.page_content for x in results])\n    augmented_prompt = f\"\"\"Using the contexts below, answer the query. If some information is not provided within\nthe contexts below, do not include, and if the query cannot be answered with the below information, say \"I don't know\".\n\nContexts:\n{source_knowledge}\n\nQuery: {query}\"\"\"\n    return augmented_prompt","metadata":{"executionCancelledAt":null,"executionTime":10,"lastExecutedAt":1698490248062,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def augment_prompt(query: str):\n    results = vectorstore.similarity_search(query, k=3)\n    source_knowledge = \"\\n\".join([x.page_content for x in results])\n    augmented_prompt = f\"\"\"Using the contexts below, answer the query. If some information is not provided within\nthe contexts below, do not include, and if the query cannot be answered with the below information, say \"I don't know\".\n\nContexts:\n{source_knowledge}\n\nQuery: {query}\"\"\"\n    return augmented_prompt"},"id":"19b86b04-9630-4fb8-a4f9-9f5b38300623","cell_type":"code","execution_count":40,"outputs":[]},{"source":"Using this we produce an augmented prompt:","metadata":{},"id":"b4a4f1a7-5d0b-4e7f-ab38-fbada51ba1d8","cell_type":"markdown"},{"source":"print(augment_prompt(query))","metadata":{"executionCancelledAt":null,"executionTime":302,"lastExecutedAt":1698490260911,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"print(augment_prompt(query))","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"id":"0ba045f5-88d7-4ce3-9ae6-e96cafa96e02","cell_type":"code","execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":"Using the contexts below, answer the query. If some information is not provided within\nthe contexts below, do not include, and if the query cannot be answered with the below information, say \"I don't know\".\n\nContexts:\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\nSergey Edunov Thomas Scialom\u0003\nGenAI, Meta\nAbstract\nIn this work, we develop and release Llama 2, a collection of pretrained and ﬁne-tuned\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\nOur ﬁne-tuned LLMs, called L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc , are optimized for dialogue use cases. Our\nmodels outperform open-source chat models on most benchmarks we tested, and based on\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosedsource models. We provide a detailed description of our approach to ﬁne-tuning and safety\nasChatGPT,BARD,andClaude. TheseclosedproductLLMsareheavilyﬁne-tunedtoalignwithhuman\npreferences, which greatly enhances their usability and safety. This step can require signiﬁcant costs in\ncomputeandhumanannotation,andisoftennottransparentoreasilyreproducible,limitingprogresswithin\nthe community to advance AI alignment research.\nIn this work, we develop and release Llama 2, a family of pretrained and ﬁne-tuned LLMs, L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle and\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc , at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested,\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc models generally perform better than existing open-source models. They also appear to\nbe on par with some of the closed-source models, at least on the human evaluations we performed (see\nBaptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aur’elien Rodriguez, Armand Joulin, Edouard\nGrave, and Guillaume Lample. Llama: Open and eﬃcient foundation language models. arXiv preprint\narXiv:2302.13971 , 2023.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser,\nand Illia Polosukhin. Attention is all you need, 2017.\nOriol Vinyals, Igor Babuschkin, Wojciech M Czarnecki, Michaël Mathieu, Andrew Dudzik, Junyoung Chung,\nDavid H Choi, Richard Powell, Timo Ewalds, Petko Georgiev, et al. Grandmaster level in starcraft ii using\nmulti-agent reinforcement learning. Nature, 575(7782):350–354, 2019.\nYizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and HannanehHajishirzi. Self-instruct: Aligninglanguagemodel withselfgeneratedinstructions. arXivpreprint\n\nQuery: What is so special about Llama 2?\n"}]},{"source":"There is still a lot of text here, so let's pass it onto our chat model to see how it performs.","metadata":{},"id":"5be7c70d-a1c2-414b-b09b-afbc046503df","cell_type":"markdown"},{"source":"prompt = HumanMessage(content=augment_prompt(query))\n\nmessages.append(prompt)\nres = chat(messages)\nprint(res.content)","metadata":{"executionCancelledAt":null,"executionTime":5775,"lastExecutedAt":1698490333721,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"prompt = HumanMessage(content=augment_prompt(query))\n\nmessages.append(prompt)\nres = chat(messages)\nprint(res.content)","outputsMetadata":{"0":{"height":277,"type":"stream"}}},"id":"6f70d2a0-d5af-448b-8f00-0aec873ac250","cell_type":"code","execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":"Based on the provided context, it is mentioned that Llama 2 is a collection of pretrained and fine-tuned large language models (LLMs) ranging from 7 billion to 70 billion parameters. These LLMs, such as L/l.sc/a.sc/m.sc/a.sc/t.sc and L/l.sc/a.sc/m.sc/a.sc/t.sc-C/h.sc/a.sc/t.sc, are optimized for dialogue use cases. The models have been evaluated and found to outperform open-source chat models on most benchmarks tested, and they are considered as potential substitutes for closed-source models in terms of helpfulness and safety.\n\nFurthermore, the authors describe their approach to fine-tuning and safety in detail, highlighting that closed-source LLMs are heavily fine-tuned to align with human preferences, enhancing their usability and safety. The development and release of Llama 2 aims to provide an open and efficient foundation for language models, allowing for advancements in AI alignment research.\n\nHowever, it's important to note that the context provided is limited, and there may be additional information about Llama 2 that is not included.\n"}]},{"source":"prompt = HumanMessage(\n    content=\"What safety measures were used in the development of llama 2?\"\n)\n\nres = chat(messages + [prompt])\nprint(res.content)","metadata":{"executionCancelledAt":null,"executionTime":4663,"lastExecutedAt":1698490475739,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"prompt = HumanMessage(\n    content=\"What safety measures were used in the development of llama 2?\"\n)\n\nres = chat(messages + [prompt])\nprint(res.content)","outputsMetadata":{"0":{"height":197,"type":"stream"}}},"id":"00e797e1-5526-416b-be41-88925fa14960","cell_type":"code","execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":"Based on the provided context, the safety measures used in the development of Llama 2 are mentioned but not explicitly described. The text mentions that the fine-tuned LLMs in Llama 2, such as L/l.sc/a.sc/m.sc/a.sc/t.sc and L/l.sc/a.sc/m.sc/a.sc/t.sc-C/h.sc/a.sc/t.sc, are optimized for dialogue use cases and appear to be on par with some closed-source models in terms of safety. It also mentions that closed-source models are heavily fine-tuned to align with human preferences, enhancing their usability and safety.\n\nHowever, the specific safety measures employed in the development of Llama 2 are not elaborated upon in the given information. It is possible that the paper or source from which this information is derived may provide more details on the safety measures utilized.\n"}]},{"source":"The chatbot is able to respond about Llama 2 thanks to it's conversational history stored in `messages`. However, it doesn't know anything about the safety measures themselves as we have not provided it with that information via the RAG pipeline. Let's try again but with RAG.","metadata":{},"id":"8ea55fa4-c8a5-436e-8934-8d90a4002c57","cell_type":"markdown"},{"source":"prompt = HumanMessage(\n    content=augment_prompt(\"What safety measures were used in the development of llama 2?\")\n)\n\nres = chat(messages + [prompt])\nprint(res.content)","metadata":{"executionCancelledAt":null,"executionTime":2855,"lastExecutedAt":1698490604812,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"prompt = HumanMessage(\n    content=augment_prompt(\"What safety measures were used in the development of llama 2?\")\n)\n\nres = chat(messages + [prompt])\nprint(res.content)","outputsMetadata":{"0":{"height":117,"type":"stream"}}},"id":"412a5fb9-5bbb-46cd-8636-6bcb7f575605","cell_type":"code","execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":"According to the provided contexts, the safety measures used in the development of Llama 2 include safety-specific data annotation and tuning, red-teaming, iterative evaluations, and a thorough approach to improving the safety of the fine-tuned large language models (LLMs). These measures were taken to increase the safety of the models and ensure responsible development of LLMs. The paper also mentions that a detailed description of their fine-tuning methodology and safety approach is provided, which can further shed light on the specific safety measures implemented.\n"}]},{"source":"We get a much better informed response that includes several items missing in the previous non-RAG response, such as \"red-teaming\", \"iterative evaluations\", and the intention of the researchers to share this research to help \"improve their safety, promoting responsible development in the field\".","metadata":{},"id":"e79d11dd-338b-4732-8315-7434a4e82d48","cell_type":"markdown"}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}